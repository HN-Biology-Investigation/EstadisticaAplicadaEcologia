---
title: ''
output:
   html_document:
         css: custom.css
header-includes:
  - \usepackage{float}
  - \floatstyle{boxed}
  - \restylefloat{figure}
  
---

<div style="display:flex; align-items:center;">
  <h1 style="margin:0;">Clase 3: Analisis de Variaza y Prueba Correlacion</h1>
  <img src="HN Cursos publicidad/HN Biology Inv Circle.jpg" alt="" style="width:100px; margin-left:20px;">
</div>


### Contenido{.tabset .tabset-pills}

#### Distribucion Normal

La distribución normal es una distribución de probabilidad continua que se utiliza comúnmente en el análisis de datos. Esta distribución es simétrica y tiene una forma de campana, con un pico en el centro y colas que se extienden hacia los valores extremos.

Para los ejercicios de esta clase, utilizaremos la base de datos  `delomys.csv`

```{r,}

delomys <- read.csv("data/delomys.csv")
```


```{r}
library(knitr)
kable(head(delomys))

```

Como se puede observar, la base de datos `delomys` presenta varias variables. Si queremos saber si alguna variable en específico presenta una distribución normal, podemos utilizar la prueba de Shapiro o realizar un gráfico cuartil-cuartil.

**Prueba de shapiro **

Es importante tener en cuenta que la prueba de normalidad de Shapiro no es infalible y puede arrojar resultados incorrectos si el tamaño de la muestra es pequeño. Por lo general, se recomienda un tamaño de muestra de al menos 30 para utilizar la prueba de Shapiro de manera fiable. Además, esta prueba puede ser sensible a los valores extremos o anómalos en los datos, por lo que puede ser necesario eliminarlos antes de realizarla.

```{r}
shapiro.test(delomys$body_mass)
```
`Es importante aplicar la prueba de normalidad para cada categoría de la variable categórica que se esté estudiando en un análisis de varianza (ANOVA). Esto se debe a que el ANOVA asume que las distribuciones de las poblaciones de las diferentes categorías son normales. Si las distribuciones no cumplen con este supuesto, los resultados del ANOVA pueden no ser válidos. Por lo tanto, antes de realizar el ANOVA, es fundamental verificar la normalidad de los datos en cada grupo para asegurar la fiabilidad de las conclusiones obtenidas.`

```{r}
shapiro.test(subset(delomys, binomial == "Delomys dorsalis")$body_mass)

shapiro.test(subset(delomys, binomial == "Delomys sublineatus")$body_mass)
```


Un gráfico de cuartil-cuartil, también conocido como gráfico Q-Q, es una herramienta gráfica utilizada para evaluar si un conjunto de datos sigue una distribución específica. En el caso de una distribución normal, se esperaría que los datos se ajusten a una línea recta en el gráfico.

```{r, fig.align='center'}
library(car)

qqPlot(delomys$body_mass)
```


```{r, fig.align='center'}
qqPlot(subset(delomys, binomial == "Delomys dorsalis")$body_mass)
```


Es importante tener en cuenta que el gráfico de cuartil-cuartil es solo una herramienta visual y no proporciona una medida cuantitativa de la normalidad de los datos. Para obtener una medida cuantitativa, se puede utilizar una prueba estadística como la prueba de Shapiro.


#### Prueba de Homogeneidad

La homogeneidad de varianzas es otro supuesto importante en muchas pruebas estadísticas. Para visualizar la homogeneidad de varianzas en una variable categórica, se puede utilizar un gráfico de caja. Sin embargo, un gráfico de dispersión es más adecuado para visualizar la homogeneidad en variables numéricas.

```{r}
library(ggplot2)

ggplot(data= delomys, aes(x= body_mass, y= body_length)) +
  geom_point()+
  geom_hline(yintercept = 114.701, linetype = "dashed")+
  geom_vline(xintercept = 44.06215, linetype = "dashed")+
  theme_classic()
```

Existen varias pruebas estadísticas para evaluar la homogeneidad de varianzas, como la prueba de Bartlett, la prueba F y la prueba de Levene.

```{r}
car::leveneTest(body_mass ~ binomial, data = delomys)
```

```{r}
library(agricolae)

bartlett.test(body_mass ~ binomial, data = delomys)
```


#### Análisis de varianza{.tabset .tabset-pilss}

El análisis de varianza (ANOVA) es una técnica estadística utilizada para evaluar si hay diferencias significativas entre dos o más grupos en una variable. Es comúnmente empleada para comparar los resultados de diferentes tratamientos o grupos de estudio en un experimento.


##### ANOVA de una vía 

El análisis de varianza (ANOVA) de una vía es una técnica estadística utilizada para evaluar si hay diferencias significativas entre dos o más grupos en una sola variable. Se emplea cuando se tienen dos o más grupos y se desea evaluar si existen diferencias significativas en una sola medida o variable.


```{r}
table(delomys$status)

ANOVA_status <- aov(body_mass ~ status, data= delomys)
summary(ANOVA_status)

```

##### ANOVA de dos vías 

El análisis de varianza (ANOVA) de dos vías es un método estadístico utilizado para comparar las diferencias entre dos o más grupos en una medida de interés. Se llama "ANOVA de dos vías" porque examina dos factores a la vez, cada uno de los cuales puede tener varios niveles o categorías.

```{r}
table(delomys$status, delomys$sex)

ANOVA_status_sex <- aov(body_mass ~ status + sex, data= delomys)
summary(ANOVA_status_sex)

```

##### MANOVA

El análisis multivariado de varianza (MANOVA) es un método estadístico utilizado para comparar las diferencias entre dos o más grupos en múltiples medidas al mismo tiempo. A diferencia del análisis de varianza (ANOVA), que se emplea para comparar diferencias entre grupos en una sola medida, el MANOVA se utiliza para comparar diferencias en varias medidas simultáneamente.

```{r}

delomys_manova <- manova(cbind(body_mass, body_length) ~ sex + status, data = delomys)

summary(delomys_manova)
```

##### ANCOVA

El análisis de covarianza (ANCOVA) es un método estadístico utilizado para comparar las diferencias entre dos o más grupos en una medida de interés, teniendo en cuenta el efecto de una o más variables covariables. Una variable covariable es aquella que puede afectar el resultado de interés y que se mide o observa al mismo tiempo que dicho resultado.


```{r}
delomys_ancova <- Anova(lm(body_mass ~ sex + status + body_length, data = delomys))

delomys_ancova
```

#### Análisis de correlación

El análisis de correlación es una técnica estadística utilizada para determinar si hay una relación entre dos variables. Esta relación se puede medir utilizando el coeficiente de correlación, que puede variar entre -1 y 1. Un coeficiente de correlación cercano a 1 indica una correlación positiva fuerte, lo que significa que, a medida que una de las variables aumenta, la otra también aumenta de manera predecible. Un coeficiente de correlación cercano a -1 indica una correlación negativa fuerte, lo que significa que, a medida que una de las variables aumenta, la otra disminuye de manera predecible. Un coeficiente de correlación cercano a 0 indica una correlación débil o nula entre las variables.

**Prueba de correlación de pearson**

```{r}
cor.test(delomys$body_mass, delomys$body_length)
```

**Prueba de correlación de spearman**

```{r}
cor.test(delomys$body_mass, delomys$body_length, method = "spearman")
```

**Grafico de correlacion**


```{r}
library(ggplot2)

ggplot(data= delomys, aes(x =body_length, y= body_mass))+
  geom_point()+
  theme_classic()
```


#### Ejercicio 

1)  Investigar para qué se utiliza y cómo se aplica la prueba T de Student.

2)  Investigar para qué se utiliza y cómo se aplica la prueba de Kruskal-Wallis.

3) Realizar la prueba de correlación utilizando la base de datos `Barn owls`

```{r}
owl <- read.table(file = "https://www.dropbox.com/s/0zpy65cr9ml47b6/owl.txt?dl=1",
                  header = TRUE, dec= ".", stringsAsFactors = T)
```


Enviar los scripts a `david.murillo@hnbiology.org`

